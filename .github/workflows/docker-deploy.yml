name: CI/CD Complète

on:
  push:
    branches:
      - main

env:
  # Configuration K3s
  K3S_VERSION: v1.26.5+k3s1
  K8S_FRONTEND_PATH: ./k8s
  NODE_PORT: 30080
  
  # Configuration Docker
  DOCKER_IMAGE: ${{ secrets.DOCKER_USERNAME }}/front_end
  CONTAINER_NAME: frontend-prod
  PORT: 80
  DOCKER_BUILDKIT: 1
  
  # Configuration SonarQube
  SONARQUBE_CONTAINER_NAME: sonarqube
  SONARQUBE_PORT: 9000
  SONARQUBE_VERSION: 10.4.1-community
  SONAR_ADMIN_PASSWORD: ${{ secrets.SONARQUBE_ADMIN_PASSWORD }}
  
  # Configuration Portainer
  PORTAINER_USER: admin
  PORTAINER_PASS: ${{ secrets.PORTAINER_PASSWORD }}
  PORTAINER_PORT: 19000
  PORTAINER_HTTPS_PORT: 19443

  # Configuration Monitoring
  GRAFANA_PORT: 30091
  PROMETHEUS_PORT: 30090
  ALERTMANAGER_PORT: 30092

jobs:
  build-app:
    runs-on: self-hosted
    timeout-minutes: 30
    steps:
      - name: 🛎 Checkout du code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: ⎔ Configurer Node.js
        uses: actions/setup-node@v3
        with:
          node-version: 18
          cache: 'npm'

      - name: 🛠️ Builder l'application
        run: |
          npm run build
          npm run test:coverage
          echo "Build généré dans dist/:"
          ls -lh dist/
          echo "Rapport de couverture dans coverage/:"
          ls -lh coverage/
          
      - name: 📦 Sauvegarder le build
        uses: actions/upload-artifact@v4
        with:
          name: react-build
          path: dist/
          retention-days: 1

  unit-tests:
    needs: build-app
    runs-on: self-hosted
    timeout-minutes: 20
    steps:
      - name: 🛎 Checkout du code
        uses: actions/checkout@v3

      - name: ⎔ Configurer Node.js
        uses: actions/setup-node@v3
        with:
          node-version: 18
          cache: 'npm'

      - name: 📦 Installer les dépendances
        run: npm ci --prefer-offline

      - name: 🧪 Exécuter les tests unitaires
        run: npm test
        env:
          CI: true
          NODE_ENV: test

  sonarqube-analysis:
    needs: unit-tests
    runs-on: self-hosted
    timeout-minutes: 40
    steps:
      - name: 🛎️ Checkout du code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: 🔍 Vérifier les rapports de test
        run: |
          echo "=== Fichiers de couverture ==="
          ls -la coverage/
          echo "=== Premières lignes du rapport LCOV ==="
          head -n 10 coverage/lcov.info || (echo "Aucun rapport LCOV trouvé" && exit 1)

      - name: 🐳 Nettoyer et démarrer SonarQube
        run: |
          # Nettoyage complet
          docker stop $SONARQUBE_CONTAINER_NAME || true
          docker rm -f $SONARQUBE_CONTAINER_NAME || true
          docker volume rm sonarqube_data sonarqube_extensions sonarqube_logs || true
          
          # Création des volumes
          docker volume create sonarqube_data
          docker volume create sonarqube_extensions
          docker volume create sonarqube_logs
          
          # Démarrage avec version plus récente
          docker run -d \
            --name $SONARQUBE_CONTAINER_NAME \
            -p $SONARQUBE_PORT:9000 \
            -v sonarqube_data:/opt/sonarqube/data \
            -v sonarqube_extensions:/opt/sonarqube/extensions \
            -v sonarqube_logs:/opt/sonarqube/logs \
            -e SONAR_ES_BOOTSTRAP_CHECKS_DISABLE=true \
            sonarqube:$SONARQUBE_VERSION

          # Attente du démarrage
          for i in {1..30}; do
            if curl -sSf http://localhost:$SONARQUBE_PORT/api/system/status | grep -q '"status":"UP"'; then
              echo "SonarQube prêt après $((i*10)) secondes"
              break
            fi
            sleep 10
          done

          # Changement du mot de passe admin
          curl -u admin:admin -X POST "http://localhost:$SONARQUBE_PORT/api/users/change_password" \
            -d "login=admin&previousPassword=admin&password=$SONAR_ADMIN_PASSWORD"

      - name: 📊 Analyser le code
        run: |
          HOST_IP=$(hostname -I | awk '{print $1}')
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          
          docker run --rm \
            --network host \
            -e SONAR_HOST_URL="http://$HOST_IP:$SONARQUBE_PORT" \
            -e SONAR_TOKEN="${{ secrets.SONARQUBE_TOKEN }}" \
            -v "$(pwd):/usr/src" \
            sonarsource/sonar-scanner-cli:latest \
            -Dsonar.projectKey=front_end_$TIMESTAMP \
            -Dsonar.projectName="FrontEnd_$TIMESTAMP" \
            -Dsonar.sources=src \
            -Dsonar.tests=src \
            -Dsonar.test.inclusions=**/*.test.{js,jsx,ts,tsx} \
            -Dsonar.javascript.lcov.reportPaths=coverage/lcov.info \
            -Dsonar.typescript.lcov.reportPaths=coverage/lcov.info \
            -Dsonar.exclusions=**/node_modules/**,**/dist/**,**/*.spec.{js,ts},**/*.test.{js,ts} \
            -Dsonar.sourceEncoding=UTF-8 \
            -Dsonar.typescript.tsconfigPath=tsconfig.json \
            -Dsonar.coverage.exclusions=**/*.test.{js,ts},**/test/** \
            -Dsonar.cpd.exclusions=**/*.test.{js,ts} \
            -Dsonar.qualitygate.wait=true

      - name: 🧹 Nettoyer les anciennes analyses
        if: always()
        run: |
          HOST_IP=$(hostname -I | awk '{print $1}')
          # Garder seulement les 5 dernières analyses
          curl -u admin:$SONAR_ADMIN_PASSWORD -sS "http://$HOST_IP:$SONARQUBE_PORT/api/projects/search?ps=100" | \
            jq -r '.components[] | select(.key | startswith("front_end_")) | .key' | \
            sort -r | \
            tail -n +6 | \
            while read -r project; do
              echo "Suppression du projet $project"
              curl -u admin:$SONAR_ADMIN_PASSWORD -X POST "http://$HOST_IP:$SONARQUBE_PORT/api/projects/delete?project=$project"
            done

  build-and-push:
    needs: sonarqube-analysis
    runs-on: self-hosted
    timeout-minutes: 30
    steps:
      - name: 🔑 Authentification Docker Hub
        run: echo "${{ secrets.DOCKER_TOKEN }}" | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin

      - name: 📥 Récupérer l'artefact
        uses: actions/download-artifact@v4
        with:
          name: react-build
          path: dist/

      - name: 🐳 Build et Push Docker
        run: |
          docker build \
            -t $DOCKER_IMAGE:latest \
            -t $DOCKER_IMAGE:$GITHUB_SHA \
            --build-arg VITE_API_BASE_URL=${{ secrets.VITE_API_BASE_URL }} \
            .
          
          docker push $DOCKER_IMAGE:latest
          docker push $DOCKER_IMAGE:$GITHUB_SHA

  deploy-docker:
    needs: build-and-push
    runs-on: self-hosted
    timeout-minutes: 20
    steps:
      - name: 🔑 Authentification Docker
        run: echo "${{ secrets.DOCKER_TOKEN }}" | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin

      - name: 🧹 Nettoyage
        run: |
          docker stop $CONTAINER_NAME || true
          docker rm -f $CONTAINER_NAME || true

      - name: 🚀 Déploiement
        run: |
          docker pull $DOCKER_IMAGE:latest
          docker run -d \
            --name $CONTAINER_NAME \
            -p $PORT:80 \
            --restart unless-stopped \
            -e NODE_ENV=production \
            $DOCKER_IMAGE:latest

      - name: ✅ Vérification
        run: |
          sleep 15
          curl -sSf http://localhost:$PORT/ || exit 1
          echo "Déploiement Docker réussi!"

  deploy-k3s:
    needs: deploy-docker
    runs-on: self-hosted
    timeout-minutes: 40
    steps:
      - name: Checkout
        uses: actions/checkout@v3
      
      - name: 🛠️ Configuration K3s
        run: |
          set -x
          sudo k3s-uninstall.sh || true
          sudo rm -rf /etc/rancher/k3s /var/lib/rancher/k3s /var/lib/cni /etc/cni/net.d/*
          
          curl -sfL https://get.k3s.io | \
            INSTALL_K3S_VERSION=$K3S_VERSION \
            sh -s - \
            --write-kubeconfig-mode 644 \
            --disable traefik \
            --node-ip $(hostname -I | awk '{print $1}') \
            --docker

      - name: 🔧 Configuration kubectl
        run: |
          mkdir -p ~/.kube
          sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
          sudo chown $USER:$USER ~/.kube/config
          sudo chmod 600 ~/.kube/config
          sed -i "s/127.0.0.1/$(hostname -I | awk '{print $1}')/g" ~/.kube/config
          
          kubectl cluster-info
          kubectl get nodes -o wide

      - name: 📌 Sauvegarde révision actuelle
        id: save-revision
        run: |
          CURRENT_REVISION=$(kubectl get deployment frontend-deployment -n frontend -o jsonpath='{.metadata.annotations.deployment\.kubernetes\.io/revision}' 2>/dev/null || echo "0")
          echo "CURRENT_REVISION=$CURRENT_REVISION" >> $GITHUB_ENV
          echo "Révision actuelle sauvegardée: $CURRENT_REVISION"

      - name: 🚀 Déploiement K8s
        run: |
          kubectl apply -f $K8S_FRONTEND_PATH/namespace.yaml
          
          export DOCKER_IMAGE=$DOCKER_IMAGE
          export TAG=$GITHUB_SHA
          
          envsubst '${DOCKER_IMAGE} ${TAG}' < $K8S_FRONTEND_PATH/deployment.yaml | kubectl apply -f -
          kubectl apply -f $K8S_FRONTEND_PATH/service.yaml

      - name: 🔍 Vérification déploiement
        id: verify-deployment
        run: |
          if kubectl wait --for=condition=available deployment/frontend-deployment -n frontend --timeout=300s; then
            echo "status=success" >> $GITHUB_OUTPUT
            kubectl get pods,svc -n frontend -o wide
            echo "Application disponible sur: http://$(hostname -I | awk '{print $1}'):$NODE_PORT"
          else
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "::error::Échec de la vérification du déploiement"
          fi

      - name: 🔄 Rollback si échec
        if: steps.verify-deployment.outputs.status == 'failure'
        run: |
          echo "::error::Lancement du rollback à la révision ${{ env.CURRENT_REVISION }}"
          kubectl rollout undo deployment/frontend-deployment -n frontend --to-revision=${{ env.CURRENT_REVISION }}
          
          echo "Vérification du rollback..."
          kubectl rollout status deployment/frontend-deployment -n frontend --timeout=180s
          
          echo "État après rollback:"
          kubectl get pods -n frontend
          exit 1

      - name: 🐳 Déploiement Portainer
        if: steps.verify-deployment.outputs.status == 'success'
        run: |
          docker stop portainer || true
          docker rm -f portainer || true
          
          docker run -d \
            --name portainer \
            -p $PORTAINER_PORT:9000 \
            -p $PORTAINER_HTTPS_PORT:9443 \
            -v /var/run/docker.sock:/var/run/docker.sock \
            -v portainer_data:/data \
            --restart unless-stopped \
            portainer/portainer-ce:latest
          
          sleep 30
          
          if ! curl -sSf http://localhost:$PORTAINER_PORT/api/users/admin/check >/dev/null; then
            curl -X POST "http://localhost:$PORTAINER_PORT/api/users/admin/init" \
              -H "Content-Type: application/json" \
              -d '{"Username": "'"$PORTAINER_USER"'", "Password": "'"$PORTAINER_PASS"'"}'
          fi
          
          AUTH_TOKEN=$(curl -s -X POST "http://localhost:$PORTAINER_PORT/api/auth" \
            -d '{"Username": "'"$PORTAINER_USER"'", "Password": "'"$PORTAINER_PASS"'"}' \
            | jq -r '.jwt')
          
          K3S_IP=$(hostname -I | awk '{print $1}')
          K3S_ENDPOINT="https://$K3S_IP:6443"
          
          K3S_CONFIG=$(sudo cat /etc/rancher/k3s/k3s.yaml | \
            sed "s/127.0.0.1/$K3S_IP/g" | \
            sed "s/default/portainer-k3s/g" | \
            base64 -w0)
          
          curl -X POST "http://localhost:$PORTAINER_PORT/api/endpoints" \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer $AUTH_TOKEN" \
            -d '{
              "Name": "K3s Cluster",
              "URL": "'"$K3S_ENDPOINT"'",
              "TLS": true,
              "TLSSkipVerify": true,
              "Type": 3,
              "KubernetesConfig": {
                "Configuration": "'"$K3S_CONFIG"'",
                "UseLoadBalancer": false
              }
            }'
            
          echo "Portainer configuré avec accès à K3s: http://$K3S_IP:$PORTAINER_PORT"

  cluster-monitoring:
    needs: deploy-k3s
    runs-on: self-hosted
    timeout-minutes: 20
    steps:
      - name: 🔧 Configurer kubectl
        run: |
          mkdir -p ~/.kube
          sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
          sudo chown $USER:$USER ~/.kube/config
          sed -i "s/127.0.0.1/$(hostname -I | awk '{print $1}')/g" ~/.kube/config

      - name: ⎈ Installer la stack monitoring
        run: |
            kubectl create namespace monitoring || true
            helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
            helm upgrade --install monitoring prometheus-community/kube-prometheus-stack \
              --namespace monitoring \
              --set grafana.adminUser="${{ secrets.GRAFANA_ADMIN_USER }}" \
              --set grafana.adminPassword="${{ secrets.GRAFANA_ADMIN_PASSWORD }}" \
              --set prometheus.service.type=NodePort \
              --set prometheus.service.nodePort=$PROMETHEUS_PORT \
              --set grafana.service.type=NodePort \
              --set grafana.service.nodePort=$GRAFANA_PORT \
              --set alertmanager.service.type=NodePort \
              --set alertmanager.service.nodePort=$ALERTMANAGER_PORT

      - name: 🌐 Afficher les accès
        run: |
          echo "=== MONITORING ==="
          echo "Grafana       : http://$(hostname -I | awk '{print $1}'):$GRAFANA_PORT"
          echo "Prometheus    : http://$(hostname -I | awk '{print $1}'):$PROMETHEUS_PORT"
          echo "AlertManager  : http://$(hostname -I | awk '{print $1}'):$ALERTMANAGER_PORT"
          echo "-----------------"
          echo "Identifiants Grafana : Voir les secrets GitHub"
          echo "=== ACCÈS APPLICATION ==="
          echo "Frontend      : http://$(hostname -I | awk '{print $1}'):$NODE_PORT"
          echo "Portainer     : http://$(hostname -I | awk '{print $1}'):$PORTAINER_PORT"